
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cWF026dDtoQUkBM-igBKo6RDgrb7WJdy
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

# Load the dataset
df = pd.read_csv('diabetes (1).csv')

print("Shape:", df.shape)
print(df.head())
print(df.describe())
print(df['Outcome'].value_counts())
print(df.groupby('Outcome').mean())

# Separating the data and labels
X = df.drop(columns='Outcome', axis=1)
y = df['Outcome']

# Correlation matrix
plt.figure(figsize=(19, 15))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# Visualizations for Glucose, Insulin, BMI, Diabetes Pedigree Function, and Age for diabetic patients
for feature in ["Glucose", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age"]:
    plt.figure(figsize=(16, 6))
    sns.histplot(df[feature][df["Outcome"] == 1], kde=True)
    plt.title(feature)
    plt.show()

# Separating dependent and independent columns
X = df.drop(["Pregnancies", "BloodPressure", "SkinThickness"], axis=1)
y = df.iloc[:, -1]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print("X_train size:", X_train.shape)
print("y_train size:", y_train.shape)
print("X_test size:", X_test.shape)
print("y_test size:", y_test.shape)

# Standard scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)  # Use transform instead of fit_transform for test set

# KNN Classifier
kn_classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)
kn_classifier.fit(X_train, y_train)
kn_y_pred = kn_classifier.predict(X_test)
cm_kn = confusion_matrix(y_test, kn_y_pred)
print("KNN Confusion Matrix:\n", cm_kn)
print("KNN Accuracy:", sum(kn_y_pred == y_test) / len(kn_y_pred))

# SVC Classifier
svc_classifier = SVC(kernel="linear", random_state=0)
svc_classifier.fit(X_train, y_train)
svc_y_pred = svc_classifier.predict(X_test)
svc_cm = confusion_matrix(y_test, svc_y_pred)
print("SVC Confusion Matrix:\n", svc_cm)
print("SVC Accuracy:", sum(svc_y_pred == y_test) / len(svc_y_pred))

# Naive Bayes Classifier
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)
nb_y_pred = nb_classifier.predict(X_test)
nb_cm = confusion_matrix(y_test, nb_y_pred)
print("Naive Bayes Confusion Matrix:\n", nb_cm)
print("Naive Bayes Accuracy:", sum(nb_y_pred == y_test) / len(nb_y_pred))

# Step 7: Store all models in a dictionary
models = {
    "knn_model": kn_classifier,
    "svc_model": svc_classifier,
    "nb_model": nb_classifier
}

#Save the trained model to a file
with open("diabetes_model.pkl", "wb") as file:
    pickle.dump(models, file)

print("Model trained and saved as 'diabetes_model.pkl'")
print(type(models))  # This should print something like <class 'sklearn.linear_model._logistic.LogisticRegression'>

